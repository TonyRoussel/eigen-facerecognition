{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Householder\n",
    "def make_householder(a):\n",
    "    u = a + np.copysign(np.linalg.norm(a), a[0])\n",
    "    v = a / u[0]\n",
    "    v[0] = 1\n",
    "    H = np.eye(a.shape[0])\n",
    "    beta = 2 / (np.dot(v, v.transpose()))\n",
    "    vtv = np.dot(np.matrix(v).transpose(), np.matrix(v))\n",
    "    H -= np.dot(beta, vtv)\n",
    "    return H\n",
    "\n",
    "def qrDecomposition(A):\n",
    "    m, n = A.shape\n",
    "    Q = np.eye(m)\n",
    "    for i in range(n - (m == n)):\n",
    "        H = np.eye(m)\n",
    "        H[i:, i:] = make_householder(A[i:, i])\n",
    "        Q = np.dot(Q, H)\n",
    "        A = np.dot(H, A)\n",
    "    return Q, A\n",
    "\n",
    "def qr(toCompute, maxIter = 100):\n",
    "    A = []\n",
    "    Q = np.eye(toCompute.shape[0])\n",
    "    A.append(None)\n",
    "    A.append(toCompute)\n",
    "    for k in range(maxIter):\n",
    "        A[0] = A[1]\n",
    "        q, R = qrDecomposition(A[0])\n",
    "        A[1] = np.dot(R, q)\n",
    "        Q = Q.dot(q)\n",
    "    return np.diagonal(A[1]), Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatMatrix(mtxLst):\n",
    "    mtx = np.array(())\n",
    "    flatLst = []\n",
    "    for m in mtxLst:\n",
    "        flatLst.append(m.flatten())\n",
    "    mtx = np.vstack(flatLst)\n",
    "    return mtx.transpose()\n",
    "\n",
    "def extractEigenvecOnVal(eigval, eigvec, threshold = 1):\n",
    "    delIdx = np.where(eigval < threshold)[0]\n",
    "    return np.delete(eigvec, delIdx, axis=1)\n",
    "\n",
    "def reconstructVector(M, eigvec):\n",
    "    eigvecT = eigvec.transpose()\n",
    "    szeNewM = (np.shape(eigvec)[1], np.shape(M)[0])\n",
    "    newmatrix = np.empty(szeNewM)\n",
    "    for idx, vec in enumerate(eigvecT):\n",
    "        newvec = np.dot(M, vec.transpose())\n",
    "        newmatrix[idx] = newvec\n",
    "    return newmatrix.transpose()\n",
    "\n",
    "def computeCostMulti(X, y, theta):\n",
    "    H = np.dot(X, theta)\n",
    "    diff = H.transpose() - y\n",
    "    diff = np.power(diff, 2)\n",
    "    sdiff = np.sum(diff, axis=1)\n",
    "    cost = sdiff / (2. * (np.shape(y)[0]))\n",
    "    return cost.item(0)\n",
    "\n",
    "def gradDescent(X, y, theta, alpha, numIter = None):\n",
    "    if numIter is None:\n",
    "        return gradDescentConvergence(X, y, theta, alpha)\n",
    "    return gradDescentIteration(X, y, theta, alpha, numIter)\n",
    "\n",
    "def gradDescentIteration(X, y, theta, alpha, numIter):\n",
    "    m = np.shape(y)[0]\n",
    "    for i in range(numIter):\n",
    "        H = np.dot(X, theta)\n",
    "        diff = H.transpose() - y\n",
    "        sigma = np.dot(X.transpose(), diff.transpose()) / m\n",
    "        theta = theta - alpha * sigma\n",
    "    print \"Last Iteration Cost: \", computeCostMulti(X, y, theta)\n",
    "    return theta\n",
    "\n",
    "def gradDescentConvergence(X, y, theta, alpha):\n",
    "    m = np.shape(y)[0]\n",
    "    i = 0\n",
    "    cost = computeCostMulti(X, y, theta)\n",
    "    costp = cost + 1\n",
    "    diff = costp - cost\n",
    "    while (diff > 1e-100):\n",
    "        H = np.dot(X, theta)\n",
    "        diff = H.transpose() - y\n",
    "        sigma = np.dot(X.transpose(), diff.transpose()) / m\n",
    "        theta = theta - alpha * sigma\n",
    "        costp = cost\n",
    "        cost = computeCostMulti(X, y, theta)\n",
    "        diff = costp - cost\n",
    "        i = i + 1\n",
    "    print \"Convergence Cost (\", i + 1,  \"iteration ): \", computeCostMulti(X, y, theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(mtxLst):\n",
    "    thetas = list()\n",
    "    M = concatMatrix(mtxLst)\n",
    "    Mmean = M.mean(axis=1)\n",
    "    M -= Mmean[:, np.newaxis]\n",
    "    Mtld = np.dot(M.transpose(), M)\n",
    "    n = np.shape(Mtld)[1]\n",
    "    #eigenval, eigenvec = qr(Mtld, 400)\n",
    "    eigenval, eigenvec = np.linalg.eig(Mtld)\n",
    "    eigenvec = extractEigenvecOnVal(eigenval, eigenvec, 1)\n",
    "    eigenvec = reconstructVector(M, eigenvec)\n",
    "    print \"eigenvec shape: \", np.shape(eigenvec)\n",
    "    thetas = np.dot(M.transpose(), eigenvec)\n",
    "    return (Mmean, eigenvec, thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learRate = 1e-11 # learnRate pour le gradient descent\n",
    "maxIteration = 10 # nombre d'iteration pour la gradient descent\n",
    "img_extension = \".pgm\"\n",
    "trainPath = \"../faceset/sample/train/\" # le nom des images doivent etre formatés tel que : [Identifiant]_[numerotation].[img_extension]\n",
    "validPath = \"../faceset/sample/valid/\" # le nom des images doivent etre formatés tel que : [Identifiant]_[numerotation].[img_extension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usleep = lambda x: time.sleep(x/1000000.0)\n",
    "\n",
    "def loadmatrixs(path):\n",
    "    matrixs = []\n",
    "    sze = len(os.listdir(path))\n",
    "    for i, filename in enumerate(os.listdir(path)):\n",
    "        if not filename.endswith(img_extension):\n",
    "            continue\n",
    "        img = misc.imread(path + filename)\n",
    "        matrixs.append((filename, img))\n",
    "        usleep(250)\n",
    "    return matrixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(mtx, mean, eigenvec):\n",
    "    mtxflat = mtx.flatten()\n",
    "    mtxflat = np.vstack(list(mtxflat))\n",
    "    mtxflat -= mean[:, np.newaxis]\n",
    "    mtxflat = mtxflat.transpose()[0]\n",
    "    theta = np.dot()\n",
    "    return theta\n",
    "\n",
    "def compare(thetaSubmit, thetas):\n",
    "    minIdx = 0\n",
    "    minVal = np.absolute(np.sum(thetas[0] - thetaSubmit))\n",
    "    for idx, theta in enumerate(thetas):\n",
    "        val = np.absolute(np.sum(np.absolute(theta - thetaSubmit)))\n",
    "        if val < minVal:\n",
    "            minIdx = idx\n",
    "            minVal = val\n",
    "    return minIdx\n",
    "\n",
    "def compareAvgGap(thetaSubmit, thetas):\n",
    "    minIdx = 0\n",
    "    minVal = (np.absolute(thetas[0] - thetaSubmit)).mean()\n",
    "    for idx, theta in enumerate(thetas):\n",
    "        val = (np.absolute(theta - thetaSubmit)).mean()\n",
    "        if val < minVal:\n",
    "            minIdx = idx\n",
    "            minVal = val\n",
    "    return minIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C'est la que tout commence\n",
    "trainD = loadmatrixs(trainPath)\n",
    "validD = loadmatrixs(validPath)\n",
    "# loadmatrixs renvoie une liste de tuple tel que : (nom_image, matrice_associée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on separe le nom des images des matrices pour l'entrainement\n",
    "ftrainD, mtrainD = zip(*trainD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvec shape:  (10304, 18)\n"
     ]
    }
   ],
   "source": [
    "# on effectue l'entrainement et on recupere: l'image moyenne, \n",
    "# les vecteurs propres utilisé pour l'entrainement, \n",
    "# les poids associé à chaque couple image/vecteurs propres\n",
    "mean, eigenvec, thetas = train(mtrainD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [ 76.75     77.75     77.5     ...,  59.59375  58.84375  59.125  ]\n",
      "eigenvec: \n",
      "[[ -7.25629058e+02  -3.16869079e+01   1.34010557e+01 ...,   2.60953592e+01\n",
      "    7.13153521e+01   2.41923249e+01]\n",
      " [ -7.25641654e+02  -3.85560812e+01   1.54007289e+01 ...,   2.34859114e+01\n",
      "    7.38651324e+01   2.12914895e+01]\n",
      " [ -6.84930213e+02   3.21835826e+01  -6.64149191e-01 ...,   7.89611079e+01\n",
      "    7.49144776e+01   5.48245773e+01]\n",
      " ..., \n",
      " [ -1.09136106e+03  -4.67480366e+01   8.59837855e+01 ...,  -4.17692459e+01\n",
      "    1.31419709e+02   8.73033005e+00]\n",
      " [ -1.04820893e+03   4.42953148e+01   5.16429657e+01 ...,  -2.94441227e+01\n",
      "    1.37878848e+02   1.50189444e+01]\n",
      " [ -1.08887510e+03  -4.93968567e+01   9.08631570e+01 ...,  -4.23480545e+01\n",
      "    1.39530295e+02   1.95504597e+01]]\n",
      "Thetas shape:  (32, 18)\n"
     ]
    }
   ],
   "source": [
    "# Pas tellement utile mais bon..c'est sympa !\n",
    "print \"Mean: \", mean\n",
    "print \"eigenvec: \\n\", eigenvec\n",
    "print \"Thetas shape: \", np.shape(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Iteration Cost:  2115928351.97\n",
      "thetaS shape:  (18, 1)\n",
      "s2_0001.pgm  -->  s1_0003.pgm [ ]\n",
      "Last Iteration Cost:  2107188754.56\n",
      "thetaS shape:  (18, 1)\n",
      "s4_0002.pgm  -->  s1_0003.pgm [ ]\n",
      "Last Iteration Cost:  2117866612.33\n",
      "thetaS shape:  (18, 1)\n",
      "s2_0002.pgm  -->  s1_0003.pgm [ ]\n",
      "Last Iteration Cost:  2193357461.22\n",
      "thetaS shape:  (18, 1)\n",
      "s3_0002.pgm  -->  s1_0003.pgm [ ]\n",
      "Last Iteration Cost:  2064378418.46\n",
      "thetaS shape:  (18, 1)\n",
      "s1_0002.pgm  -->  s1_0003.pgm [X]\n",
      "Last Iteration Cost:  2025098417.7\n",
      "thetaS shape:  (18, 1)\n",
      "s1_0001.pgm  -->  s1_0003.pgm [X]\n",
      "Last Iteration Cost:  2094906468.21\n",
      "thetaS shape:  (18, 1)\n",
      "s4_0001.pgm  -->  s1_0003.pgm [ ]\n",
      "Last Iteration Cost:  2210542876.04\n",
      "thetaS shape:  (18, 1)\n",
      "s3_0001.pgm  -->  s1_0003.pgm [ ]\n"
     ]
    }
   ],
   "source": [
    "# On boucle sur la liste de tuples de validation\n",
    "count = 0\n",
    "for idx, data in enumerate(validD):\n",
    "    success = False\n",
    "    filename, mtx = data\n",
    "    # on effectue la gradient descent sur chaque image de validation avec les vecteurs propres precedement calculé, \n",
    "    # et on recupere les poids associé\n",
    "    thetaSubmit = submit(mtx, mean, eigenvec)\n",
    "    print \"thetaS shape: \", np.shape(thetaSubmit)\n",
    "    # on recherche l'index de l'ensemble de poids issue de l'entrainement, ce rapprochant le plus des poids qui viennent\n",
    "    # d'etre calculé\n",
    "    matchIdx = compareAvgGap(thetaSubmit, thetas)\n",
    "    # grace a l'index que l'on viens de recuperer, on compare le nom de l'image de validation\n",
    "    # et le nom de l'image matché\n",
    "    if filename[:filename.rfind(\"_\")] == ftrainD[matchIdx][:ftrainD[matchIdx].rfind(\"_\")]:\n",
    "        success = True\n",
    "        count = count + 1\n",
    "    if success is True:\n",
    "        print filename, \" --> \", ftrainD[matchIdx], \"[X]\"\n",
    "    else:\n",
    "        print filename, \" --> \", ftrainD[matchIdx], \"[ ]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18  /  18 ===> 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# bah la ca affiche le taux de reussite\n",
    "print count, \" / \", idx + 1, \"===>\", count / (idx + 1.) * 100, \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
